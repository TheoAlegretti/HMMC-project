{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a58e5522",
   "metadata": {},
   "source": [
    "# Packages installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6297fa6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install packages needed \n",
    "!pip install matplotlib\n",
    "!pip install particles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae8cb38",
   "metadata": {},
   "source": [
    "# Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a836eb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "\n",
    "# Modules from particles\n",
    "import particles \n",
    "from particles import distributions as dists # Where proba distributions are defined\n",
    "from particles import state_space_models as ssm # Where state-space-models are defined\n",
    "from particles.collectors import Moments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7991946c",
   "metadata": {},
   "source": [
    "# A word about what we are trying to achieve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cefb409",
   "metadata": {},
   "source": [
    "Generally, for the type of problems we are speaking about, we deal with:\n",
    "- An hidden variable $X_t$ that follows a markov process. This variable can be multivariate. It is characterized by a **transition kernel**.\n",
    "- An observed variable $Y_t$ whose distribution depends on $X_t$. It is characterized by an **emission law**. \n",
    "\n",
    "The basic task is, given that we *know* the transition kernel, the emission law, and all their parameters, to recover the $X_t$ based on a sequence of $Y_t$ (*filtering* / *complete smoothing*).\n",
    "\n",
    "A more challening tasks is to perform **bayesian inference**, that is, to estimate the posterior of the parameters given the data (and prior on the parameters). This task relies on particle MCMC algorithms. \n",
    "\n",
    "In our setting: \n",
    "\n",
    "- $X$ is composed of \n",
    "    - $u_t$, the expression level. It is the variable that, in real life, researchers are trying to recover. \n",
    "    - $s_t$, the local scaling term. A variable that follows a markov process independently from everything else and will be useful at some point. \n",
    "- $Y$ is simply $y_t$, the read counts. It is basically **a noisy observation of $u_t$**. Its distribution is described by the **emission law** that involves $u_t$ and $s_t$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332ff127",
   "metadata": {},
   "source": [
    "What we have to do \n",
    "1. **Describe the model using the pacakge particles.**\n",
    "    - This means we have to \"code\" the initial law $X_0$ (which we will chose somehow, not that important), the Markov transition kernel of $X_t$ and the emission law of $Y_t$. The two last one are described thoroughly in the **supplementary materials** of the paper, but we might have technical difficulties for implementing it. \n",
    "    - Then, we will be able to *generate* observations using the model.\n",
    "   \n",
    "2. **Implement a particle filter with a fixed $\\Theta$**\n",
    "    - That is, recoverint $X_t$ based on $Y_t$, in a situation where all the parameter values are known.\n",
    "\n",
    "3. **Implement two ways to do bayesian inference on the model.**\n",
    "    - That is, estimate the values of the parameters.\n",
    "    - **Implementation 1**: Particle Gibbs (like in the paper)\n",
    "    - **Implementation 2**: PMMH (simpler to implement but harder to calibrate). \n",
    "    - And compare those two implementations.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c1669d",
   "metadata": {},
   "source": [
    "# Creating our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63e0f22",
   "metadata": {},
   "source": [
    "## On the use of uniforms to make \"choices\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29886fd1",
   "metadata": {},
   "source": [
    "Here, we rely on the \"particles\" package for the distributions. \n",
    "The following is the code that allows to draw a number from a uniform continuous distribution on [0,1]. \n",
    "Note that first we $define$ the law (as an object), then we can generate numbers from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4d2626b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05535058]\n",
      "[0.64745081]\n"
     ]
    }
   ],
   "source": [
    "Uniform = dists.Uniform(a = 0, b = 1)\n",
    "# Generate one number from a (continuous) uniform(0,1)\n",
    "x = Uniform.rvs(size = 1)\n",
    "print(x)\n",
    "\n",
    "# Equivalently\n",
    "y = dists.Uniform(a = 0., b = 1.).rvs(size = 1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dce6bbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a bunch of uniforms \n",
    "vector_x = Uniform.rvs(size = 10000)\n",
    "#plt.hist(vector_x, density = True, bins = 100)\n",
    "#plt.show()\n",
    "\n",
    "# Equivalently \n",
    "vector_y = dists.Uniform(a = 0., b = 1.).rvs(size = 10000)\n",
    "#plt.hist(vector_y, density = True, bins = 100)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef58ee4b",
   "metadata": {},
   "source": [
    "In our case, uniforms have two different uses:\n",
    "- We can create more complex distributions based on uniforms (see next section for more details)\n",
    "- We can use them to make **choices**\n",
    "    \n",
    "The markov transition kernels for $u_{t}$ consists in a mixture of different possible **moves**. If, for example, $u_{t-1} = 0$, $u_t$ either stays at 0 (with probability $1 - \\eta$) or follows an exponential distribution (with probability $\\eta$). In our implementation, it is necessary, at each step, to choose between these options.\n",
    "\n",
    "One way to do it is to generate a uniform $u \\sim \\mathcal{U}(0,1)$, then to check if $ u < \\eta$. If so, $u_{t}$ should follow an exponential, if not, it should stay at 0.\n",
    "\n",
    "This procedure can be extended to multiple moves. Say we have 3 options, with respective probabilities $\\alpha$, $\\beta$ and $\\gamma$ such that $\\alpha + \\beta + \\gamma = 1$. First we generate $u \\sim \\mathcal{U}(0,1)$. Then we check:\n",
    "- $u < \\alpha$ ? If so: option 1, if not, continue the loop.\n",
    "- $u < \\alpha + \\beta$ ? If so:option 2, if not, continue the loop.\n",
    "- Given that probabilities sum up to 1, the only possibility left is option 3. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e6bc19",
   "metadata": {},
   "source": [
    "## About the distributions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2c40bd",
   "metadata": {},
   "source": [
    "All probability distributions are not available in the package (see the documentation https://particles-sequential-monte-carlo-in-python.readthedocs.io/en/latest/distributions.html). However, it is possible to define **transformations** of distributions and, as such, to create new ones. The two next transformations will prove useful. \n",
    "\n",
    "If $X \\sim \\mathcal{U}(0,1)$ then $-\\frac{1}{\\lambda} log X \\sim \\mathcal{E}(\\lambda)$ (here, $\\lambda$ is the **rate**). \n",
    "\n",
    "If $Y \\sim \\mathcal{G}a(n, \\frac{1-p}{p})$ and $ X|y \\sim \\mathcal{P}(y)$ then $X \\sim \\mathcal{N}eg(n,p)$  \n",
    "\n",
    "The following pieces of codes are used to generate such laws using the functions in the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086f4352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exponential with rate zeta \n",
    "zeta = 2\n",
    "exp_zeta = dists.LinearD(dists.LogD(dists.Uniform(a = 0., b = 1.)), a = - 1 / zeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "49d81142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative Binomial n,p\n",
    "\n",
    "# Need to check the parametrization of gammas and NG we are talking about !\n",
    "# Unsure if that is possible using the pacakge, considering the transforms are linear, not compositions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dff9ceb",
   "metadata": {},
   "source": [
    "## Actual definition of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef74edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class expression(ssm.StateSpaceModel):\n",
    "    \n",
    "    \"\"\"\n",
    "    # Work in progress. In the end, we should add default values of the parameters here. \n",
    "    default_params = {\"eta\":, \"alpha\":, \"beta\":, \"beta_0\", \"gamma_u\":, \"gamma_d\":,\n",
    "                     \"zeta\":, \"lamba_u\":, \"lambda_d\": ,\n",
    "                     \"alpha_s\":, \"kappa_s\":}\n",
    "    \"\"\"\n",
    "    \n",
    "    # Initial distribution of the data (X0)\n",
    "    def PX0(self): \n",
    "    \n",
    "    \n",
    "    # Transition kernel \n",
    "    def PX(self, t, xp): # Distribution of X_t given X_{t-1} = xp (p = past)\n",
    "        # Here, X involves two things: u_t (0th index) and s_t (1th index)\n",
    "        # Therefore, we have to define both \n",
    "        \n",
    "        # For u_t \n",
    "        \n",
    "        uni_x = dists.Uniform(a = 0, b = 1).rvs(size = 1) # Uniform to \"choose a move\"\n",
    "        \n",
    "        if xp[:,0] ==0 :\n",
    "            if uni <= self.eta:\n",
    "                # Dirac on xp = 0 \n",
    "                u_t =  dists.Dirac(loc = 0)\n",
    "            else:\n",
    "                # Exponential law with rate zeta \n",
    "                u_t = dists.LinearD(dists.LogD(dists.Uniform(a = 0, b = 1)), a = - 1 / zeta)\n",
    "            \n",
    "        elif xp[:,0] !=0:\n",
    "            if uni <= alpha:\n",
    "                # Dirac on xp\n",
    "                u_t = dists.Dirac(loc = xp[:, 0])\n",
    "                \n",
    "            elif uni <= alpha + beta:\n",
    "                # Exponential law with rate zeta \n",
    "                u_t = dists.LinearD(dists.LogD(dists.Uniform(a = 0, b = 1)), a = - 1 / zeta)\n",
    "            \n",
    "            elif uni <= alpha + beta + beta_0:\n",
    "                # Dirac on 0\n",
    "                u_t = dists.Dirac(loc = 0)\n",
    "            \n",
    "            elif uni <= alpha + beta + beta_0 + gamma_u:\n",
    "                #\n",
    "                u_t = \n",
    "            \n",
    "            else:\n",
    "                #\n",
    "                u_t = \n",
    "                \n",
    "        #For s_t\n",
    "        \n",
    "        uni_s = dists.Uniform(a = 0, b = 1).rvs(size = 1) # Uniform to \"choose\" a move \n",
    "        if uni_s <= alpha_s:\n",
    "            s_t = dists.Dirac(loc = xp[:,1])\n",
    "        else:\n",
    "            s_t = dists.Gamma(a = kappa_s, b = kappa_s)\n",
    "        \n",
    "        # Return the independant product of u_t and s_t\n",
    "        return IndeProd(u_t, s_t)\n",
    "\n",
    "            \n",
    "    # Emission model\n",
    "    def PY(self, t, xp, x): # Distribution of Y_t given X_t = x (and possibly X_{t-1} =xp)\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
